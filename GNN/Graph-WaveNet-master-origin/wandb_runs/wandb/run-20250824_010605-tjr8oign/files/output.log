Ê£ÄÊµãÂà∞ÂêàÊàêÊï∞ÊçÆÈõÜÔºöSYNTHETIC_EASY
ÈÖçÁΩÆÂèÇÊï∞: ËäÇÁÇπÊï∞=12, ÈÇªÊé•Áü©Èòµ=data/sensor_graph/adj_mx_synthetic_easy.pkl
üèãÔ∏è ËøêË°åÂçï‰∏™ÂÆûÈ™å...
üìä ÈÖçÁΩÆ: seq_length=12, pred_length=12
üîÑ ‰∏∫ seq_length=12, pred_length=12 ÁîüÊàêÊï∞ÊçÆ...
‚ö†Ô∏è  ‰∏çÊîØÊåÅÁöÑÊï∞ÊçÆÈõÜÁ±ªÂûã: DATA/SYNTHETIC_EASY
Ë∑≥ËøáÊï∞ÊçÆÁîüÊàêÔºå‰ΩøÁî®Áé∞ÊúâÊï∞ÊçÆ...
Namespace(addaptadj=True, adjdata='data/sensor_graph/adj_mx_synthetic_easy.pkl', adjtype='doubletransition', aptonly=False, batch_size=64, data='data/SYNTHETIC_EASY', device='cuda:0', dropout=0.3, epochs=50, expid=1, gcn_bool=True, in_dim=2, learning_rate=0.001, nhid=32, num_nodes=12, pred_length=12, print_every=50, randomadj=True, run_multiple_experiments=False, save='./garage/synth_easy/', seq_length=12, weight_decay=0.0001)
start training...
Iter: 000, Train Loss: 0.4618, Train MAPE: 0.0118, Train RMSE: 0.5553
Epoch: 001, Inference Time: 0.1037 secs
Epoch: 001, Train Loss: 0.3679, Train MAPE: 0.0694, Train RMSE: 0.5065, Valid Loss: 0.4003, Valid MAPE: -0.0132, Valid RMSE: 0.5179, Training Time: 3.2838/epoch
Iter: 000, Train Loss: 0.3408, Train MAPE: 0.0760, Train RMSE: 0.4904
Epoch: 002, Inference Time: 0.0989 secs
Epoch: 002, Train Loss: 0.3294, Train MAPE: 0.1033, Train RMSE: 0.4922, Valid Loss: 0.3852, Valid MAPE: 0.0446, Valid RMSE: 0.5203, Training Time: 0.9537/epoch
Iter: 000, Train Loss: 0.3222, Train MAPE: 0.1024, Train RMSE: 0.4936
Epoch: 003, Inference Time: 0.0987 secs
Epoch: 003, Train Loss: 0.3226, Train MAPE: 0.0767, Train RMSE: 0.4881, Valid Loss: 0.3751, Valid MAPE: 0.0834, Valid RMSE: 0.5309, Training Time: 0.9418/epoch
Iter: 000, Train Loss: 0.3295, Train MAPE: 0.0844, Train RMSE: 0.4978
Epoch: 004, Inference Time: 0.1016 secs
Epoch: 004, Train Loss: 0.3182, Train MAPE: 0.0923, Train RMSE: 0.4844, Valid Loss: 0.3698, Valid MAPE: 0.0863, Valid RMSE: 0.5402, Training Time: 0.9534/epoch
Iter: 000, Train Loss: 0.3214, Train MAPE: 0.1264, Train RMSE: 0.4928
Epoch: 005, Inference Time: 0.0989 secs
Epoch: 005, Train Loss: 0.3144, Train MAPE: 0.0788, Train RMSE: 0.4788, Valid Loss: 0.3704, Valid MAPE: 0.1025, Valid RMSE: 0.5492, Training Time: 0.9491/epoch
Iter: 000, Train Loss: 0.3149, Train MAPE: 0.0566, Train RMSE: 0.4811
Epoch: 006, Inference Time: 0.0989 secs
Epoch: 006, Train Loss: 0.3111, Train MAPE: 0.0784, Train RMSE: 0.4770, Valid Loss: 0.3679, Valid MAPE: 0.0794, Valid RMSE: 0.5426, Training Time: 0.9427/epoch
Iter: 000, Train Loss: 0.2967, Train MAPE: 0.0251, Train RMSE: 0.4482
Epoch: 007, Inference Time: 0.0992 secs
Epoch: 007, Train Loss: 0.3070, Train MAPE: 0.0684, Train RMSE: 0.4720, Valid Loss: 0.3672, Valid MAPE: 0.0726, Valid RMSE: 0.5384, Training Time: 0.9414/epoch
Iter: 000, Train Loss: 0.3092, Train MAPE: 0.1159, Train RMSE: 0.4644
Epoch: 008, Inference Time: 0.0991 secs
Epoch: 008, Train Loss: 0.3038, Train MAPE: 0.0641, Train RMSE: 0.4682, Valid Loss: 0.3699, Valid MAPE: 0.1053, Valid RMSE: 0.5479, Training Time: 0.9418/epoch
Iter: 000, Train Loss: 0.2990, Train MAPE: 0.0464, Train RMSE: 0.4666
Epoch: 009, Inference Time: 0.0990 secs
Epoch: 009, Train Loss: 0.2994, Train MAPE: 0.0703, Train RMSE: 0.4644, Valid Loss: 0.3692, Valid MAPE: 0.0816, Valid RMSE: 0.5397, Training Time: 0.9442/epoch
Iter: 000, Train Loss: 0.2940, Train MAPE: -0.0165, Train RMSE: 0.4447
Epoch: 010, Inference Time: 0.0988 secs
Epoch: 010, Train Loss: 0.2969, Train MAPE: 0.0635, Train RMSE: 0.4605, Valid Loss: 0.3717, Valid MAPE: 0.0846, Valid RMSE: 0.5376, Training Time: 0.9414/epoch
Iter: 000, Train Loss: 0.3071, Train MAPE: 0.0284, Train RMSE: 0.4733
Epoch: 011, Inference Time: 0.0988 secs
Epoch: 011, Train Loss: 0.2937, Train MAPE: 0.0601, Train RMSE: 0.4549, Valid Loss: 0.3749, Valid MAPE: 0.1089, Valid RMSE: 0.5450, Training Time: 0.9409/epoch
Iter: 000, Train Loss: 0.2988, Train MAPE: 0.1051, Train RMSE: 0.4607
Epoch: 012, Inference Time: 0.0990 secs
Epoch: 012, Train Loss: 0.2894, Train MAPE: 0.0670, Train RMSE: 0.4506, Valid Loss: 0.3758, Valid MAPE: 0.0876, Valid RMSE: 0.5509, Training Time: 0.9419/epoch
Iter: 000, Train Loss: 0.2957, Train MAPE: 0.0560, Train RMSE: 0.4591
Epoch: 013, Inference Time: 0.0989 secs
Epoch: 013, Train Loss: 0.2850, Train MAPE: 0.0655, Train RMSE: 0.4464, Valid Loss: 0.3790, Valid MAPE: 0.1026, Valid RMSE: 0.5566, Training Time: 0.9463/epoch
Iter: 000, Train Loss: 0.2790, Train MAPE: 0.0596, Train RMSE: 0.4425
Epoch: 014, Inference Time: 0.0989 secs
Epoch: 014, Train Loss: 0.2807, Train MAPE: 0.0616, Train RMSE: 0.4399, Valid Loss: 0.3801, Valid MAPE: 0.1092, Valid RMSE: 0.5537, Training Time: 0.9413/epoch
Iter: 000, Train Loss: 0.2665, Train MAPE: 0.1514, Train RMSE: 0.4243
Epoch: 015, Inference Time: 0.0995 secs
Epoch: 015, Train Loss: 0.2777, Train MAPE: 0.0624, Train RMSE: 0.4357, Valid Loss: 0.3833, Valid MAPE: 0.1099, Valid RMSE: 0.5533, Training Time: 0.9415/epoch
Iter: 000, Train Loss: 0.2744, Train MAPE: 0.1376, Train RMSE: 0.4279
Epoch: 016, Inference Time: 0.1008 secs
Epoch: 016, Train Loss: 0.2756, Train MAPE: 0.0674, Train RMSE: 0.4321, Valid Loss: 0.3817, Valid MAPE: 0.1065, Valid RMSE: 0.5478, Training Time: 0.9423/epoch
Iter: 000, Train Loss: 0.2460, Train MAPE: 0.1085, Train RMSE: 0.3840
Epoch: 017, Inference Time: 0.0994 secs
Epoch: 017, Train Loss: 0.2705, Train MAPE: 0.0550, Train RMSE: 0.4262, Valid Loss: 0.3843, Valid MAPE: 0.1215, Valid RMSE: 0.5560, Training Time: 0.9427/epoch
Iter: 000, Train Loss: 0.2664, Train MAPE: 0.1073, Train RMSE: 0.4220
Epoch: 018, Inference Time: 0.0989 secs
Epoch: 018, Train Loss: 0.2660, Train MAPE: 0.0678, Train RMSE: 0.4232, Valid Loss: 0.3860, Valid MAPE: 0.0864, Valid RMSE: 0.5617, Training Time: 0.9426/epoch
Iter: 000, Train Loss: 0.2717, Train MAPE: 0.0479, Train RMSE: 0.4403
Epoch: 019, Inference Time: 0.0988 secs
Epoch: 019, Train Loss: 0.2633, Train MAPE: 0.0622, Train RMSE: 0.4198, Valid Loss: 0.3850, Valid MAPE: 0.0947, Valid RMSE: 0.5561, Training Time: 0.9413/epoch
Iter: 000, Train Loss: 0.2538, Train MAPE: 0.0421, Train RMSE: 0.4089
Epoch: 020, Inference Time: 0.0989 secs
Epoch: 020, Train Loss: 0.2601, Train MAPE: 0.0646, Train RMSE: 0.4157, Valid Loss: 0.3880, Valid MAPE: 0.1128, Valid RMSE: 0.5612, Training Time: 0.9412/epoch
Iter: 000, Train Loss: 0.2583, Train MAPE: 0.0765, Train RMSE: 0.4196
Epoch: 021, Inference Time: 0.0989 secs
Epoch: 021, Train Loss: 0.2571, Train MAPE: 0.0617, Train RMSE: 0.4122, Valid Loss: 0.3900, Valid MAPE: 0.1423, Valid RMSE: 0.5630, Training Time: 0.9408/epoch
Iter: 000, Train Loss: 0.2620, Train MAPE: 0.0759, Train RMSE: 0.4184
Epoch: 022, Inference Time: 0.0990 secs
Epoch: 022, Train Loss: 0.2534, Train MAPE: 0.0694, Train RMSE: 0.4078, Valid Loss: 0.3884, Valid MAPE: 0.0841, Valid RMSE: 0.5579, Training Time: 0.9413/epoch
Iter: 000, Train Loss: 0.2474, Train MAPE: 0.0600, Train RMSE: 0.4016
Epoch: 023, Inference Time: 0.0989 secs
Epoch: 023, Train Loss: 0.2511, Train MAPE: 0.0676, Train RMSE: 0.4056, Valid Loss: 0.3893, Valid MAPE: 0.1017, Valid RMSE: 0.5628, Training Time: 0.9405/epoch
Iter: 000, Train Loss: 0.2440, Train MAPE: 0.0498, Train RMSE: 0.3934
Epoch: 024, Inference Time: 0.0988 secs
Epoch: 024, Train Loss: 0.2482, Train MAPE: 0.0663, Train RMSE: 0.4029, Valid Loss: 0.3899, Valid MAPE: 0.1197, Valid RMSE: 0.5600, Training Time: 0.9403/epoch
Iter: 000, Train Loss: 0.2482, Train MAPE: 0.0926, Train RMSE: 0.4051
Epoch: 025, Inference Time: 0.0992 secs
Epoch: 025, Train Loss: 0.2466, Train MAPE: 0.0706, Train RMSE: 0.4006, Valid Loss: 0.3886, Valid MAPE: 0.1069, Valid RMSE: 0.5593, Training Time: 0.9404/epoch
Iter: 000, Train Loss: 0.2570, Train MAPE: 0.0620, Train RMSE: 0.4203
Epoch: 026, Inference Time: 0.0990 secs
Epoch: 026, Train Loss: 0.2429, Train MAPE: 0.0687, Train RMSE: 0.3967, Valid Loss: 0.3943, Valid MAPE: 0.1106, Valid RMSE: 0.5645, Training Time: 0.9455/epoch
Iter: 000, Train Loss: 0.2414, Train MAPE: 0.0947, Train RMSE: 0.3933
Epoch: 027, Inference Time: 0.0987 secs
Epoch: 027, Train Loss: 0.2410, Train MAPE: 0.0678, Train RMSE: 0.3939, Valid Loss: 0.3908, Valid MAPE: 0.1157, Valid RMSE: 0.5614, Training Time: 0.9412/epoch
Iter: 000, Train Loss: 0.2400, Train MAPE: 0.1262, Train RMSE: 0.3873
Epoch: 028, Inference Time: 0.0991 secs
Epoch: 028, Train Loss: 0.2387, Train MAPE: 0.0699, Train RMSE: 0.3917, Valid Loss: 0.3954, Valid MAPE: 0.1146, Valid RMSE: 0.5654, Training Time: 0.9410/epoch
Iter: 000, Train Loss: 0.2272, Train MAPE: 0.1092, Train RMSE: 0.3785
Epoch: 029, Inference Time: 0.0988 secs
Epoch: 029, Train Loss: 0.2367, Train MAPE: 0.0705, Train RMSE: 0.3898, Valid Loss: 0.3934, Valid MAPE: 0.0903, Valid RMSE: 0.5659, Training Time: 0.9413/epoch
Iter: 000, Train Loss: 0.2462, Train MAPE: 0.0427, Train RMSE: 0.4041
Epoch: 030, Inference Time: 0.0989 secs
Epoch: 030, Train Loss: 0.2352, Train MAPE: 0.0766, Train RMSE: 0.3867, Valid Loss: 0.3951, Valid MAPE: 0.0703, Valid RMSE: 0.5640, Training Time: 0.9414/epoch
Iter: 000, Train Loss: 0.2331, Train MAPE: 0.0414, Train RMSE: 0.3833
Epoch: 031, Inference Time: 0.0989 secs
Epoch: 031, Train Loss: 0.2335, Train MAPE: 0.0685, Train RMSE: 0.3851, Valid Loss: 0.3974, Valid MAPE: 0.1167, Valid RMSE: 0.5624, Training Time: 0.9419/epoch
Iter: 000, Train Loss: 0.2269, Train MAPE: 0.0596, Train RMSE: 0.3698
Epoch: 032, Inference Time: 0.0989 secs
Epoch: 032, Train Loss: 0.2306, Train MAPE: 0.0737, Train RMSE: 0.3818, Valid Loss: 0.3979, Valid MAPE: 0.1377, Valid RMSE: 0.5680, Training Time: 0.9411/epoch
Iter: 000, Train Loss: 0.2202, Train MAPE: 0.0772, Train RMSE: 0.3725
Epoch: 033, Inference Time: 0.0998 secs
Epoch: 033, Train Loss: 0.2288, Train MAPE: 0.0719, Train RMSE: 0.3795, Valid Loss: 0.3988, Valid MAPE: 0.1489, Valid RMSE: 0.5658, Training Time: 0.9411/epoch
Iter: 000, Train Loss: 0.2365, Train MAPE: 0.1104, Train RMSE: 0.3864
Epoch: 034, Inference Time: 0.0991 secs
Epoch: 034, Train Loss: 0.2272, Train MAPE: 0.0771, Train RMSE: 0.3778, Valid Loss: 0.3968, Valid MAPE: 0.0901, Valid RMSE: 0.5639, Training Time: 0.9445/epoch
Iter: 000, Train Loss: 0.2171, Train MAPE: 0.0580, Train RMSE: 0.3657
Epoch: 035, Inference Time: 0.0989 secs
Epoch: 035, Train Loss: 0.2256, Train MAPE: 0.0773, Train RMSE: 0.3754, Valid Loss: 0.3954, Valid MAPE: 0.0893, Valid RMSE: 0.5635, Training Time: 0.9410/epoch
Iter: 000, Train Loss: 0.2290, Train MAPE: 0.0704, Train RMSE: 0.3803
Epoch: 036, Inference Time: 0.0989 secs
Epoch: 036, Train Loss: 0.2244, Train MAPE: 0.0734, Train RMSE: 0.3740, Valid Loss: 0.4004, Valid MAPE: 0.1126, Valid RMSE: 0.5706, Training Time: 0.9405/epoch
Iter: 000, Train Loss: 0.2045, Train MAPE: 0.0989, Train RMSE: 0.3474
Epoch: 037, Inference Time: 0.0989 secs
Epoch: 037, Train Loss: 0.2221, Train MAPE: 0.0750, Train RMSE: 0.3713, Valid Loss: 0.4014, Valid MAPE: 0.1315, Valid RMSE: 0.5625, Training Time: 0.9403/epoch
Iter: 000, Train Loss: 0.2154, Train MAPE: 0.0557, Train RMSE: 0.3663
Epoch: 038, Inference Time: 0.0989 secs
Epoch: 038, Train Loss: 0.2220, Train MAPE: 0.0706, Train RMSE: 0.3701, Valid Loss: 0.4007, Valid MAPE: 0.1104, Valid RMSE: 0.5743, Training Time: 0.9411/epoch
Iter: 000, Train Loss: 0.2165, Train MAPE: 0.0931, Train RMSE: 0.3681
Epoch: 039, Inference Time: 0.0989 secs
Epoch: 039, Train Loss: 0.2222, Train MAPE: 0.0766, Train RMSE: 0.3721, Valid Loss: 0.3972, Valid MAPE: 0.1354, Valid RMSE: 0.5599, Training Time: 0.9412/epoch
Iter: 000, Train Loss: 0.1980, Train MAPE: 0.0818, Train RMSE: 0.3362
Epoch: 040, Inference Time: 0.0989 secs
Epoch: 040, Train Loss: 0.2179, Train MAPE: 0.0780, Train RMSE: 0.3666, Valid Loss: 0.3949, Valid MAPE: 0.1067, Valid RMSE: 0.5626, Training Time: 0.9412/epoch
Iter: 000, Train Loss: 0.2137, Train MAPE: 0.0583, Train RMSE: 0.3680
Epoch: 041, Inference Time: 0.0989 secs
Epoch: 041, Train Loss: 0.2158, Train MAPE: 0.0768, Train RMSE: 0.3642, Valid Loss: 0.4051, Valid MAPE: 0.1042, Valid RMSE: 0.5666, Training Time: 0.9411/epoch
Iter: 000, Train Loss: 0.2139, Train MAPE: 0.0880, Train RMSE: 0.3595
Epoch: 042, Inference Time: 0.0991 secs
Epoch: 042, Train Loss: 0.2143, Train MAPE: 0.0785, Train RMSE: 0.3613, Valid Loss: 0.4010, Valid MAPE: 0.1523, Valid RMSE: 0.5734, Training Time: 0.9408/epoch
Iter: 000, Train Loss: 0.2262, Train MAPE: 0.0902, Train RMSE: 0.3840
Epoch: 043, Inference Time: 0.0989 secs
Epoch: 043, Train Loss: 0.2127, Train MAPE: 0.0774, Train RMSE: 0.3622, Valid Loss: 0.4037, Valid MAPE: 0.1275, Valid RMSE: 0.5665, Training Time: 0.9405/epoch
Iter: 000, Train Loss: 0.1935, Train MAPE: 0.0721, Train RMSE: 0.3404
Epoch: 044, Inference Time: 0.0997 secs
Epoch: 044, Train Loss: 0.2108, Train MAPE: 0.0757, Train RMSE: 0.3585, Valid Loss: 0.4003, Valid MAPE: 0.1349, Valid RMSE: 0.5651, Training Time: 0.9432/epoch
Iter: 000, Train Loss: 0.2058, Train MAPE: 0.0736, Train RMSE: 0.3559
Epoch: 045, Inference Time: 0.0991 secs
Epoch: 045, Train Loss: 0.2116, Train MAPE: 0.0786, Train RMSE: 0.3596, Valid Loss: 0.4050, Valid MAPE: 0.1375, Valid RMSE: 0.5781, Training Time: 0.9410/epoch
Iter: 000, Train Loss: 0.2091, Train MAPE: 0.0883, Train RMSE: 0.3590
Epoch: 046, Inference Time: 0.0988 secs
Epoch: 046, Train Loss: 0.2083, Train MAPE: 0.0846, Train RMSE: 0.3557, Valid Loss: 0.4021, Valid MAPE: 0.1558, Valid RMSE: 0.5630, Training Time: 0.9409/epoch
Iter: 000, Train Loss: 0.2188, Train MAPE: 0.1180, Train RMSE: 0.3642
Epoch: 047, Inference Time: 0.0989 secs
Epoch: 047, Train Loss: 0.2079, Train MAPE: 0.0818, Train RMSE: 0.3535, Valid Loss: 0.4049, Valid MAPE: 0.1145, Valid RMSE: 0.5791, Training Time: 0.9406/epoch
Iter: 000, Train Loss: 0.1987, Train MAPE: 0.0776, Train RMSE: 0.3460
Epoch: 048, Inference Time: 0.0988 secs
Epoch: 048, Train Loss: 0.2079, Train MAPE: 0.0827, Train RMSE: 0.3544, Valid Loss: 0.4052, Valid MAPE: 0.1260, Valid RMSE: 0.5712, Training Time: 0.9452/epoch
Iter: 000, Train Loss: 0.2006, Train MAPE: 0.0915, Train RMSE: 0.3446
Epoch: 049, Inference Time: 0.0991 secs
Epoch: 049, Train Loss: 0.2059, Train MAPE: 0.0851, Train RMSE: 0.3525, Valid Loss: 0.4064, Valid MAPE: 0.1290, Valid RMSE: 0.5696, Training Time: 0.9407/epoch
Iter: 000, Train Loss: 0.2063, Train MAPE: 0.0918, Train RMSE: 0.3522
Epoch: 050, Inference Time: 0.0988 secs
Epoch: 050, Train Loss: 0.2037, Train MAPE: 0.0812, Train RMSE: 0.3490, Valid Loss: 0.4039, Valid MAPE: 0.1530, Valid RMSE: 0.5687, Training Time: 0.9410/epoch
Average Training Time: 0.9892 secs/epoch
Average Inference Time: 0.0992 secs
Traceback (most recent call last):
  File "train.py", line 1070, in <module>
    result = main_experiment()
  File "train.py", line 898, in main_experiment
    engine.model.load_state_dict(torch.load(args.save+"_epoch_"+str(bestid+1)+"_"+str(round(his_loss[bestid],2))+".pth"))
  File "/mnt/webscistorage/cc7738/anaconda3/envs/Energy-TSF/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1604, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for gwnet:
	size mismatch for filter_convs.0.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.1.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.2.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.3.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.4.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.5.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.6.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.7.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.0.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.1.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.2.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.3.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.4.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.5.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.6.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.7.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.0.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.1.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.2.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.3.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.4.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.5.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.6.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.7.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for skip_convs.0.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.1.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.2.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.3.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.4.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.4.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.5.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.5.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.6.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.6.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.7.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.7.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for bn.0.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.0.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.0.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.3.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.3.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.4.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.4.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.4.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.5.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.5.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.5.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.6.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.6.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.6.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.7.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.7.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.7.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.0.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.0.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.1.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.1.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.2.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.2.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.3.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.3.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.4.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.4.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.5.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.5.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.6.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.6.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.7.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.7.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for start_conv.weight: copying a param with shape torch.Size([64, 2, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 2, 1, 1]).
	size mismatch for start_conv.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for end_conv_1.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).
	size mismatch for end_conv_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for end_conv_2.weight: copying a param with shape torch.Size([12, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([12, 512, 1, 1]).
