Ê£ÄÊµãÂà∞ÂêàÊàêÊï∞ÊçÆÈõÜÔºöSYNTHETIC_EASY
ÈÖçÁΩÆÂèÇÊï∞: ËäÇÁÇπÊï∞=12, ÈÇªÊé•Áü©Èòµ=data/sensor_graph/adj_mx_synthetic_easy.pkl
üèãÔ∏è ËøêË°åÂçï‰∏™ÂÆûÈ™å...
üìä ÈÖçÁΩÆ: seq_length=12, pred_length=12
üîÑ ‰∏∫ seq_length=12, pred_length=12 ÁîüÊàêÊï∞ÊçÆ...
‚ö†Ô∏è  ‰∏çÊîØÊåÅÁöÑÊï∞ÊçÆÈõÜÁ±ªÂûã: DATA/SYNTHETIC_EASY
Ë∑≥ËøáÊï∞ÊçÆÁîüÊàêÔºå‰ΩøÁî®Áé∞ÊúâÊï∞ÊçÆ...
Namespace(addaptadj=True, adjdata='data/sensor_graph/adj_mx_synthetic_easy.pkl', adjtype='doubletransition', aptonly=False, batch_size=64, data='data/SYNTHETIC_EASY', device='cuda:0', dropout=0.3, epochs=50, expid=1, gcn_bool=True, in_dim=2, learning_rate=0.0005, nhid=32, num_nodes=12, pred_length=12, print_every=50, randomadj=True, run_multiple_experiments=False, save='./garage/synth_easy/', seq_length=12, weight_decay=0.0001)
start training...
Iter: 000, Train Loss: 0.4416, Train MAPE: -0.0556, Train RMSE: 0.5460
Epoch: 001, Inference Time: 0.0976 secs
Epoch: 001, Train Loss: 0.3812, Train MAPE: -0.0130, Train RMSE: 0.5126, Valid Loss: 0.3995, Valid MAPE: 0.0010, Valid RMSE: 0.5163, Training Time: 3.2095/epoch
Iter: 000, Train Loss: 0.3382, Train MAPE: 0.2030, Train RMSE: 0.4828
Epoch: 002, Inference Time: 0.0976 secs
Epoch: 002, Train Loss: 0.3356, Train MAPE: 0.1163, Train RMSE: 0.4912, Valid Loss: 0.3854, Valid MAPE: 0.0232, Valid RMSE: 0.5178, Training Time: 0.9319/epoch
Iter: 000, Train Loss: 0.3210, Train MAPE: 0.0828, Train RMSE: 0.4829
Epoch: 003, Inference Time: 0.0976 secs
Epoch: 003, Train Loss: 0.3263, Train MAPE: 0.0977, Train RMSE: 0.4903, Valid Loss: 0.3721, Valid MAPE: 0.0583, Valid RMSE: 0.5279, Training Time: 0.9281/epoch
Iter: 000, Train Loss: 0.3232, Train MAPE: 0.1137, Train RMSE: 0.4911
Epoch: 004, Inference Time: 0.0976 secs
Epoch: 004, Train Loss: 0.3219, Train MAPE: 0.0893, Train RMSE: 0.4878, Valid Loss: 0.3679, Valid MAPE: 0.0726, Valid RMSE: 0.5396, Training Time: 0.9278/epoch
Iter: 000, Train Loss: 0.3206, Train MAPE: 0.1033, Train RMSE: 0.4865
Epoch: 005, Inference Time: 0.0976 secs
Epoch: 005, Train Loss: 0.3193, Train MAPE: 0.0888, Train RMSE: 0.4849, Valid Loss: 0.3679, Valid MAPE: 0.0785, Valid RMSE: 0.5442, Training Time: 0.9301/epoch
Iter: 000, Train Loss: 0.3225, Train MAPE: 0.0529, Train RMSE: 0.4892
Epoch: 006, Inference Time: 0.0976 secs
Epoch: 006, Train Loss: 0.3167, Train MAPE: 0.0811, Train RMSE: 0.4823, Valid Loss: 0.3679, Valid MAPE: 0.0811, Valid RMSE: 0.5474, Training Time: 0.9280/epoch
Iter: 000, Train Loss: 0.3046, Train MAPE: 0.0845, Train RMSE: 0.4656
Epoch: 007, Inference Time: 0.0975 secs
Epoch: 007, Train Loss: 0.3140, Train MAPE: 0.0780, Train RMSE: 0.4795, Valid Loss: 0.3708, Valid MAPE: 0.0916, Valid RMSE: 0.5530, Training Time: 0.9283/epoch
Iter: 000, Train Loss: 0.3177, Train MAPE: 0.0547, Train RMSE: 0.4861
Epoch: 008, Inference Time: 0.0976 secs
Epoch: 008, Train Loss: 0.3111, Train MAPE: 0.0730, Train RMSE: 0.4772, Valid Loss: 0.3713, Valid MAPE: 0.0960, Valid RMSE: 0.5537, Training Time: 0.9297/epoch
Iter: 000, Train Loss: 0.3021, Train MAPE: 0.1419, Train RMSE: 0.4639
Epoch: 009, Inference Time: 0.0975 secs
Epoch: 009, Train Loss: 0.3092, Train MAPE: 0.0660, Train RMSE: 0.4743, Valid Loss: 0.3692, Valid MAPE: 0.0693, Valid RMSE: 0.5478, Training Time: 0.9283/epoch
Iter: 000, Train Loss: 0.3056, Train MAPE: 0.0412, Train RMSE: 0.4741
Epoch: 010, Inference Time: 0.0976 secs
Epoch: 010, Train Loss: 0.3073, Train MAPE: 0.0678, Train RMSE: 0.4726, Valid Loss: 0.3704, Valid MAPE: 0.0888, Valid RMSE: 0.5496, Training Time: 0.9267/epoch
Iter: 000, Train Loss: 0.2982, Train MAPE: 0.1000, Train RMSE: 0.4690
Epoch: 011, Inference Time: 0.0975 secs
Epoch: 011, Train Loss: 0.3043, Train MAPE: 0.0653, Train RMSE: 0.4702, Valid Loss: 0.3706, Valid MAPE: 0.0848, Valid RMSE: 0.5504, Training Time: 0.9298/epoch
Iter: 000, Train Loss: 0.3051, Train MAPE: 0.0428, Train RMSE: 0.4718
Epoch: 012, Inference Time: 0.0975 secs
Epoch: 012, Train Loss: 0.3021, Train MAPE: 0.0652, Train RMSE: 0.4663, Valid Loss: 0.3696, Valid MAPE: 0.0846, Valid RMSE: 0.5480, Training Time: 0.9331/epoch
Iter: 000, Train Loss: 0.3078, Train MAPE: 0.0618, Train RMSE: 0.4695
Epoch: 013, Inference Time: 0.0975 secs
Epoch: 013, Train Loss: 0.2997, Train MAPE: 0.0650, Train RMSE: 0.4639, Valid Loss: 0.3711, Valid MAPE: 0.0881, Valid RMSE: 0.5504, Training Time: 0.9276/epoch
Iter: 000, Train Loss: 0.2877, Train MAPE: 0.0139, Train RMSE: 0.4574
Epoch: 014, Inference Time: 0.0975 secs
Epoch: 014, Train Loss: 0.2965, Train MAPE: 0.0656, Train RMSE: 0.4604, Valid Loss: 0.3696, Valid MAPE: 0.0859, Valid RMSE: 0.5476, Training Time: 0.9291/epoch
Iter: 000, Train Loss: 0.2867, Train MAPE: 0.0919, Train RMSE: 0.4493
Epoch: 015, Inference Time: 0.0989 secs
Epoch: 015, Train Loss: 0.2939, Train MAPE: 0.0677, Train RMSE: 0.4567, Valid Loss: 0.3689, Valid MAPE: 0.0865, Valid RMSE: 0.5474, Training Time: 0.9437/epoch
Iter: 000, Train Loss: 0.2991, Train MAPE: 0.0573, Train RMSE: 0.4614
Epoch: 016, Inference Time: 0.1048 secs
Epoch: 016, Train Loss: 0.2914, Train MAPE: 0.0631, Train RMSE: 0.4526, Valid Loss: 0.3701, Valid MAPE: 0.0859, Valid RMSE: 0.5489, Training Time: 0.9488/epoch
Iter: 000, Train Loss: 0.2813, Train MAPE: 0.0522, Train RMSE: 0.4490
Epoch: 017, Inference Time: 0.0982 secs
Epoch: 017, Train Loss: 0.2906, Train MAPE: 0.0638, Train RMSE: 0.4529, Valid Loss: 0.3715, Valid MAPE: 0.1015, Valid RMSE: 0.5489, Training Time: 0.9460/epoch
Iter: 000, Train Loss: 0.2955, Train MAPE: 0.1032, Train RMSE: 0.4634
Epoch: 018, Inference Time: 0.0977 secs
Epoch: 018, Train Loss: 0.2880, Train MAPE: 0.0637, Train RMSE: 0.4490, Valid Loss: 0.3690, Valid MAPE: 0.0975, Valid RMSE: 0.5444, Training Time: 0.9246/epoch
Iter: 000, Train Loss: 0.2773, Train MAPE: 0.0846, Train RMSE: 0.4446
Epoch: 019, Inference Time: 0.0978 secs
Epoch: 019, Train Loss: 0.2855, Train MAPE: 0.0661, Train RMSE: 0.4474, Valid Loss: 0.3696, Valid MAPE: 0.0896, Valid RMSE: 0.5385, Training Time: 0.9238/epoch
Iter: 000, Train Loss: 0.2754, Train MAPE: 0.0631, Train RMSE: 0.4312
Epoch: 020, Inference Time: 0.0978 secs
Epoch: 020, Train Loss: 0.2822, Train MAPE: 0.0630, Train RMSE: 0.4420, Valid Loss: 0.3693, Valid MAPE: 0.0812, Valid RMSE: 0.5426, Training Time: 0.9232/epoch
Iter: 000, Train Loss: 0.2919, Train MAPE: 0.0500, Train RMSE: 0.4522
Epoch: 021, Inference Time: 0.0978 secs
Epoch: 021, Train Loss: 0.2799, Train MAPE: 0.0621, Train RMSE: 0.4384, Valid Loss: 0.3746, Valid MAPE: 0.1002, Valid RMSE: 0.5544, Training Time: 0.9236/epoch
Iter: 000, Train Loss: 0.3054, Train MAPE: 0.0394, Train RMSE: 0.4796
Epoch: 022, Inference Time: 0.0979 secs
Epoch: 022, Train Loss: 0.2786, Train MAPE: 0.0674, Train RMSE: 0.4377, Valid Loss: 0.3724, Valid MAPE: 0.0886, Valid RMSE: 0.5513, Training Time: 0.9326/epoch
Iter: 000, Train Loss: 0.2865, Train MAPE: 0.0262, Train RMSE: 0.4548
Epoch: 023, Inference Time: 0.0977 secs
Epoch: 023, Train Loss: 0.2759, Train MAPE: 0.0652, Train RMSE: 0.4349, Valid Loss: 0.3697, Valid MAPE: 0.0833, Valid RMSE: 0.5407, Training Time: 0.9277/epoch
Iter: 000, Train Loss: 0.2684, Train MAPE: -0.0154, Train RMSE: 0.4284
Epoch: 024, Inference Time: 0.0977 secs
Epoch: 024, Train Loss: 0.2728, Train MAPE: 0.0643, Train RMSE: 0.4314, Valid Loss: 0.3729, Valid MAPE: 0.0960, Valid RMSE: 0.5465, Training Time: 0.9232/epoch
Iter: 000, Train Loss: 0.2607, Train MAPE: 0.0560, Train RMSE: 0.4163
Epoch: 025, Inference Time: 0.0977 secs
Epoch: 025, Train Loss: 0.2720, Train MAPE: 0.0702, Train RMSE: 0.4305, Valid Loss: 0.3734, Valid MAPE: 0.1052, Valid RMSE: 0.5473, Training Time: 0.9227/epoch
Iter: 000, Train Loss: 0.2777, Train MAPE: 0.0519, Train RMSE: 0.4394
Epoch: 026, Inference Time: 0.0978 secs
Epoch: 026, Train Loss: 0.2691, Train MAPE: 0.0658, Train RMSE: 0.4268, Valid Loss: 0.3725, Valid MAPE: 0.0889, Valid RMSE: 0.5463, Training Time: 0.9229/epoch
Iter: 000, Train Loss: 0.2599, Train MAPE: 0.0339, Train RMSE: 0.4212
Epoch: 027, Inference Time: 0.0978 secs
Epoch: 027, Train Loss: 0.2667, Train MAPE: 0.0640, Train RMSE: 0.4253, Valid Loss: 0.3721, Valid MAPE: 0.0658, Valid RMSE: 0.5445, Training Time: 0.9252/epoch
Iter: 000, Train Loss: 0.2808, Train MAPE: 0.0419, Train RMSE: 0.4419
Epoch: 028, Inference Time: 0.0975 secs
Epoch: 028, Train Loss: 0.2649, Train MAPE: 0.0686, Train RMSE: 0.4232, Valid Loss: 0.3731, Valid MAPE: 0.0542, Valid RMSE: 0.5451, Training Time: 0.9232/epoch
Iter: 000, Train Loss: 0.2499, Train MAPE: -0.0162, Train RMSE: 0.4056
Epoch: 029, Inference Time: 0.0977 secs
Epoch: 029, Train Loss: 0.2656, Train MAPE: 0.0621, Train RMSE: 0.4225, Valid Loss: 0.3755, Valid MAPE: 0.1069, Valid RMSE: 0.5460, Training Time: 0.9254/epoch
Iter: 000, Train Loss: 0.2641, Train MAPE: 0.0747, Train RMSE: 0.4194
Epoch: 030, Inference Time: 0.0977 secs
Epoch: 030, Train Loss: 0.2618, Train MAPE: 0.0705, Train RMSE: 0.4196, Valid Loss: 0.3763, Valid MAPE: 0.0826, Valid RMSE: 0.5502, Training Time: 0.9235/epoch
Iter: 000, Train Loss: 0.2737, Train MAPE: 0.0640, Train RMSE: 0.4328
Epoch: 031, Inference Time: 0.0977 secs
Epoch: 031, Train Loss: 0.2605, Train MAPE: 0.0715, Train RMSE: 0.4170, Valid Loss: 0.3741, Valid MAPE: 0.0766, Valid RMSE: 0.5449, Training Time: 0.9220/epoch
Iter: 000, Train Loss: 0.2639, Train MAPE: 0.0160, Train RMSE: 0.4156
Epoch: 032, Inference Time: 0.0978 secs
Epoch: 032, Train Loss: 0.2589, Train MAPE: 0.0665, Train RMSE: 0.4155, Valid Loss: 0.3751, Valid MAPE: 0.1042, Valid RMSE: 0.5419, Training Time: 0.9222/epoch
Iter: 000, Train Loss: 0.2481, Train MAPE: 0.1136, Train RMSE: 0.3960
Epoch: 033, Inference Time: 0.0977 secs
Epoch: 033, Train Loss: 0.2576, Train MAPE: 0.0718, Train RMSE: 0.4138, Valid Loss: 0.3767, Valid MAPE: 0.0885, Valid RMSE: 0.5428, Training Time: 0.9230/epoch
Iter: 000, Train Loss: 0.2581, Train MAPE: 0.0701, Train RMSE: 0.4119
Epoch: 034, Inference Time: 0.0976 secs
Epoch: 034, Train Loss: 0.2562, Train MAPE: 0.0709, Train RMSE: 0.4124, Valid Loss: 0.3794, Valid MAPE: 0.1158, Valid RMSE: 0.5475, Training Time: 0.9227/epoch
Iter: 000, Train Loss: 0.2527, Train MAPE: 0.1094, Train RMSE: 0.4083
Epoch: 035, Inference Time: 0.0974 secs
Epoch: 035, Train Loss: 0.2543, Train MAPE: 0.0709, Train RMSE: 0.4091, Valid Loss: 0.3792, Valid MAPE: 0.1105, Valid RMSE: 0.5475, Training Time: 0.9224/epoch
Iter: 000, Train Loss: 0.2333, Train MAPE: 0.0960, Train RMSE: 0.3899
Epoch: 036, Inference Time: 0.0977 secs
Epoch: 036, Train Loss: 0.2529, Train MAPE: 0.0695, Train RMSE: 0.4086, Valid Loss: 0.3797, Valid MAPE: 0.0850, Valid RMSE: 0.5494, Training Time: 0.9244/epoch
Iter: 000, Train Loss: 0.2703, Train MAPE: 0.0216, Train RMSE: 0.4266
Epoch: 037, Inference Time: 0.0974 secs
Epoch: 037, Train Loss: 0.2520, Train MAPE: 0.0713, Train RMSE: 0.4068, Valid Loss: 0.3792, Valid MAPE: 0.1084, Valid RMSE: 0.5436, Training Time: 0.9225/epoch
Iter: 000, Train Loss: 0.2503, Train MAPE: 0.0807, Train RMSE: 0.4015
Epoch: 038, Inference Time: 0.0975 secs
Epoch: 038, Train Loss: 0.2504, Train MAPE: 0.0779, Train RMSE: 0.4040, Valid Loss: 0.3790, Valid MAPE: 0.1006, Valid RMSE: 0.5437, Training Time: 0.9220/epoch
Iter: 000, Train Loss: 0.2407, Train MAPE: 0.0762, Train RMSE: 0.3878
Epoch: 039, Inference Time: 0.0975 secs
Epoch: 039, Train Loss: 0.2498, Train MAPE: 0.0720, Train RMSE: 0.4037, Valid Loss: 0.3808, Valid MAPE: 0.0969, Valid RMSE: 0.5514, Training Time: 0.9219/epoch
Iter: 000, Train Loss: 0.2526, Train MAPE: 0.0652, Train RMSE: 0.4161
Epoch: 040, Inference Time: 0.0974 secs
Epoch: 040, Train Loss: 0.2462, Train MAPE: 0.0758, Train RMSE: 0.4010, Valid Loss: 0.3816, Valid MAPE: 0.1124, Valid RMSE: 0.5506, Training Time: 0.9219/epoch
Iter: 000, Train Loss: 0.2426, Train MAPE: 0.0838, Train RMSE: 0.4037
Epoch: 041, Inference Time: 0.0977 secs
Epoch: 041, Train Loss: 0.2439, Train MAPE: 0.0743, Train RMSE: 0.3986, Valid Loss: 0.3833, Valid MAPE: 0.1198, Valid RMSE: 0.5508, Training Time: 0.9216/epoch
Iter: 000, Train Loss: 0.2406, Train MAPE: 0.1053, Train RMSE: 0.3936
Epoch: 042, Inference Time: 0.0975 secs
Epoch: 042, Train Loss: 0.2432, Train MAPE: 0.0795, Train RMSE: 0.3971, Valid Loss: 0.3811, Valid MAPE: 0.0768, Valid RMSE: 0.5489, Training Time: 0.9219/epoch
Iter: 000, Train Loss: 0.2284, Train MAPE: 0.0680, Train RMSE: 0.3768
Epoch: 043, Inference Time: 0.0974 secs
Epoch: 043, Train Loss: 0.2421, Train MAPE: 0.0770, Train RMSE: 0.3960, Valid Loss: 0.3819, Valid MAPE: 0.1057, Valid RMSE: 0.5470, Training Time: 0.9224/epoch
Iter: 000, Train Loss: 0.2411, Train MAPE: 0.1024, Train RMSE: 0.3851
Epoch: 044, Inference Time: 0.0974 secs
Epoch: 044, Train Loss: 0.2421, Train MAPE: 0.0757, Train RMSE: 0.3941, Valid Loss: 0.3834, Valid MAPE: 0.1080, Valid RMSE: 0.5494, Training Time: 0.9216/epoch
Iter: 000, Train Loss: 0.2444, Train MAPE: 0.0719, Train RMSE: 0.3957
Epoch: 045, Inference Time: 0.0974 secs
Epoch: 045, Train Loss: 0.2391, Train MAPE: 0.0749, Train RMSE: 0.3919, Valid Loss: 0.3837, Valid MAPE: 0.1051, Valid RMSE: 0.5504, Training Time: 0.9225/epoch
Iter: 000, Train Loss: 0.2398, Train MAPE: 0.0940, Train RMSE: 0.3930
Epoch: 046, Inference Time: 0.0977 secs
Epoch: 046, Train Loss: 0.2378, Train MAPE: 0.0784, Train RMSE: 0.3908, Valid Loss: 0.3838, Valid MAPE: 0.0983, Valid RMSE: 0.5500, Training Time: 0.9246/epoch
Iter: 000, Train Loss: 0.2403, Train MAPE: 0.0695, Train RMSE: 0.3970
Epoch: 047, Inference Time: 0.0975 secs
Epoch: 047, Train Loss: 0.2372, Train MAPE: 0.0739, Train RMSE: 0.3894, Valid Loss: 0.3844, Valid MAPE: 0.1113, Valid RMSE: 0.5505, Training Time: 0.9223/epoch
Iter: 000, Train Loss: 0.2381, Train MAPE: 0.0802, Train RMSE: 0.3976
Epoch: 048, Inference Time: 0.0974 secs
Epoch: 048, Train Loss: 0.2346, Train MAPE: 0.0776, Train RMSE: 0.3863, Valid Loss: 0.3872, Valid MAPE: 0.1217, Valid RMSE: 0.5491, Training Time: 0.9215/epoch
Iter: 000, Train Loss: 0.2424, Train MAPE: 0.0729, Train RMSE: 0.3902
Epoch: 049, Inference Time: 0.0975 secs
Epoch: 049, Train Loss: 0.2339, Train MAPE: 0.0788, Train RMSE: 0.3859, Valid Loss: 0.3847, Valid MAPE: 0.0881, Valid RMSE: 0.5495, Training Time: 0.9216/epoch
Iter: 000, Train Loss: 0.2240, Train MAPE: 0.0448, Train RMSE: 0.3670
Epoch: 050, Inference Time: 0.0977 secs
Epoch: 050, Train Loss: 0.2335, Train MAPE: 0.0766, Train RMSE: 0.3852, Valid Loss: 0.3874, Valid MAPE: 0.0729, Valid RMSE: 0.5498, Training Time: 0.9214/epoch
Average Training Time: 0.9719 secs/epoch
Average Inference Time: 0.0978 secs
Traceback (most recent call last):
  File "train.py", line 1070, in <module>
    result = main_experiment()
  File "train.py", line 898, in main_experiment
    engine.model.load_state_dict(torch.load(args.save+"_epoch_"+str(bestid+1)+"_"+str(round(his_loss[bestid],2))+".pth"))
  File "/mnt/webscistorage/cc7738/anaconda3/envs/Energy-TSF/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1604, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for gwnet:
	size mismatch for filter_convs.0.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.1.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.2.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.3.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.4.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.5.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.6.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for filter_convs.7.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for filter_convs.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.0.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.1.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.2.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.3.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.4.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.5.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.6.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gate_convs.7.weight: copying a param with shape torch.Size([64, 64, 1, 2]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 2]).
	size mismatch for gate_convs.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.0.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.1.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.2.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.3.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.4.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.5.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.6.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for residual_convs.7.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).
	size mismatch for residual_convs.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for skip_convs.0.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.1.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.2.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.3.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.4.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.4.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.5.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.5.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.6.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.6.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for skip_convs.7.weight: copying a param with shape torch.Size([512, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 32, 1, 1]).
	size mismatch for skip_convs.7.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for bn.0.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.0.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.0.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.0.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.2.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.2.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.2.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.3.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.3.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.3.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.3.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.4.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.4.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.4.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.4.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.5.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.5.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.5.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.5.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.6.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.6.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.6.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.7.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.7.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.7.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for bn.7.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.0.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.0.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.1.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.1.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.2.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.2.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.3.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.3.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.4.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.4.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.5.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.5.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.6.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.6.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for gconv.7.mlp.mlp.weight: copying a param with shape torch.Size([64, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 224, 1, 1]).
	size mismatch for gconv.7.mlp.mlp.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for start_conv.weight: copying a param with shape torch.Size([64, 2, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 2, 1, 1]).
	size mismatch for start_conv.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for end_conv_1.weight: copying a param with shape torch.Size([1024, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).
	size mismatch for end_conv_1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for end_conv_2.weight: copying a param with shape torch.Size([12, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([12, 512, 1, 1]).
